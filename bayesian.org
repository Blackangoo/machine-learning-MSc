#+TITLE:     Bayesian Inference and Hypothesis Testing
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \usepackage{tikz}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{amssymb}
#+LaTeX_HEADER: \usepackage{isomath}
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Var {\mathop{\mbox{\ensuremath{\mathbb{V}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Bias {\mathop{\mbox{\ensuremath{\mathbb{B}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \DeclareMathOperator*{\sgn}{sgn}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Params {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+LaTeX_HEADER: \newcommand \vparam {\vectorsym{\theta}}
#+LaTeX_HEADER: \newcommand \mparam {\matrixsym{\Theta}}
#+LaTeX_HEADER: \newcommand \bW {\matrixsym{W}}
#+LaTeX_HEADER: \newcommand \bw {\vectorsym{w}}
#+LaTeX_HEADER: \newcommand \wi {\vectorsym{w}_i}
#+LaTeX_HEADER: \newcommand \wij {w_{i,j}}
#+LaTeX_HEADER: \newcommand \bA {\matrixsym{A}}
#+LaTeX_HEADER: \newcommand \ai {\vectorsym{a}_i}
#+LaTeX_HEADER: \newcommand \aij {a_{i,j}}
#+LaTeX_HEADER: \newcommand \bx {\vectorsym{x}}
#+LaTeX_HEADER: \newcommand \pol {\pi}
#+LaTeX_HEADER: \newcommand \Pols {\Pi}
#+LaTeX_HEADER: \newcommand \bel {\beta}
#+LaTeX_HEADER: \newcommand \Ber {\textrm{Bernoulli}}
#+LaTeX_HEADER: \newcommand \Beta {\textrm{Beta}}
#+LaTeX_HEADER: \newcommand \Normal {\textrm{Normal}}
#+LaTeX_CLASS_OPTIONS: [smaller]
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:2
#+OPTIONS: toc:nil

* Conditional Probability and the Theorem of Bayes
#+TOC: headlines
** Bayes theorem                                         :theory:probability:
#+ATTR_BEAMER: :overlay <+->
- Recall the definition of Conditional probability:
 \[
 P(A | B) = P(A \cap B) / P(B)
 \]
 i.e. the probability of A happening if B happens.
- It is also true that:
 \[
 P(B | A) = P(A \cap B) / P(A)
 \]
- Combining the two equations, reverse the conditioning:
 \[
 P(A | B) = P(B | A) P (A) / P(B)
 \]

- So we can reverse the order of conditioning, i.e. relate to the probability of A given B to that of B given A.

* Conditional probability example
#+TOC: headlines
** The cards problem
 1. Print out a number of cards, with either [A|A], [A|B] or [B|B] on their sides.
 2. If you have an A, what is the probability of an A on the other side?
 3. Have the students perform the experiment with:
    1. Draw a random card.
    2. Count the number of people with A.
    3. What is the probability that somebody with an A on one side will have an A on the other?
    4. Half of the people should have an A?
#+BEAMER: \pause

*** The prior and posterior probabilities
	| A | A | 2/6 | A observed | 2/3
	| A | B | 1/6 | A observed | 1/3
	| B | A | 1/6 |            |
	| B | B | 2/6 |            |

* Bayesian analysis example
#+TOC: headlines
** The murder problem
#+ATTR_BEAMER: :overlay <+->
- Somebody saw somebody matching their description and he was found
       in the neighbourghood. There is no other evidence.

- There are two possibilities:
       - $H_0$: They are innocent.
       - $H_1$: They are guilty.

       What is your belief that they have committed the crime? 
	
*** Prior elicitation
#+ATTR_BEAMER: :overlay <+->
- All those that think the accused is guilty, raise their hand.
- Divide by the number of people in class
- Let us call this $P(H_1)$.
- This is a purely subjective measure!

** DNA test

 - Let us now do a DNA test on the suspect
#+BEAMER: \pause

*** DNA test properties
 #+ATTR_BEAMER: :overlay <+->
 - $D$: Test is positive
 - $P(D | H_0) = 1\%$: False positive rate
 - $P(D | H_1) = 100\%$: True positive rate

#+BEAMER: \pause

*** Run the test
#+ATTR_BEAMER: :overlay <+->
- The result is either positive or negative ($\neg D)$.
- What is your belief *now* that the suspect is guilty?

** Everybody is a suspect
       #+ATTR_BEAMER: :overlay <+->
- Run a DNA test on everybody.
- What is different from before?
- Who has a positive test?
- What is your belief that the people with the positive test are guilty?

** Explanation
       #+ATTR_BEAMER: :overlay <+->
- Prior: $P(H_i)$.
- Likelihood $P(D | H_i)$.
- Posterior: $P(H_i | D) = P(D \cap H_i) / P(D) = P(D | H_i) P(H_i) / P(D)$
- Marginal probability: $P(D) = P(D | H_0) P(H_0) + P(D | H_1) P(H_1)$
- Posterior: $P(H_0 | D) = \frac{P(D | H_0) P(H_0)}{P(D | H_0) P(H_0) + P(D | H_1) P(H_1)}$
- Assuming $P(D | H_1) = 1$, and setting $P(H_0) = q$, this gives
       \[
       P(H_0 | D) = \frac{0.1 q}{0.1 q + 1 - q} =  \frac{q}{10 - 9q}
       \]
- The posterior can always be updated with more data!
** Python example

#+BEGIN_SRC python
# the input to the function is the prior, the likelihood function, and posteriors
# Input:
# - prior for hypothesis 0 (scalar)
# - data (single data point)
# - likelihood[data][hypothesis] array unction
# Returns:
# - posterior for the data point (if multiple points are given, the calculation is repeated)
def get_posterior(prior, data, likelihood):
    marginal = prior * likelihood[data][0] + (1 - prior) * likelihood[data][1]
    posterior = prior * likelihood[data][0] / marginal
    return posterior

import numpy as np
prior = 0.9
likelihood = np.zeros([2, 2])
# pr of negative test if not a match
likelihood[0][0] = 0.9
# pr of positive test if not a match
likelihood[1][0] = 0.1
# pr of negative test if a match
likelihood[0][1] = 0
# pr of positive test if a match
likelihood[1][1] = 1
data = 1
return get_posterior(prior, data, likelihood)
#+END_SRC

#+RESULTS:
: 0.4736842105263158

* More general problems
#+TOC: headlines
** The $k$ meteorologists problem


We have $k$ meteorological stations. 
*** Predictions and outcomes
| Station      |   M |   T |   W |   T |
|--------------+-----+-----+-----+-----|
| MeteoSuisse  | 25% | 20% | 10% |  5% |
| Wunderground | 30% | 50% | 20% | 10% |
| AccuWeather  | 90% | 70% | 10% |  0% |
|--------------+-----+-----+-----+-----|
| Rain         |   Y |   N |   N |   Y |

*** $H_i$: The \(i\)-th station's model is correct
- $P(H_i)$: prior
- $P(D | H_i)$: likelihood according to station $i$
- $P(H_i | D)$: posterior

** Types of hypothesis testing problems
#+ATTR_BEAMER: :overlay <+->
*** Simple Hypothesis Test
#+ATTR_BEAMER: :overlay <+->
Example: DNA evidence, Covid tests
- Two hypothesese $H_0, H_1$
- $P(D | H_i)$ is defined for all $i$

*** Multiple Hypotheses Test
#+ATTR_BEAMER: :overlay <+->
Example: Model selection
- $H_i$: One of many mutually exclusive models
- $P(D | H_i)$ is defined for all $i$

*** Null Hypothesis Test
#+ATTR_BEAMER: :overlay <+->
Example: Are men's and women's heights the same?
- $H_0$: The 'null' hypothesis
- $P(D | H_0)$ is defined
- The alternative is *undefined*

** Pitfalls
#+ATTR_BEAMER: :overlay <+->

*** Problem definition
#+ATTR_BEAMER: :overlay <+->
- Defining the models $P(D | H_i)$ incorrectly.
- Using an "unreasonable" prior $P(H_i)$

*** The garden of many paths
#+ATTR_BEAMER: :overlay <+->
- Having a huge hypothesis space
- Selecting the relevant hypothesis after seeing the data


* Bayesian Inference
** Bayesian Inference
*** Bayesian Machine Learning
- Model family $\{P_\param |  \param \in \Params\}$
- Each model $\param$ assigns a score (i.e. a probability) $P_\param(x)$ to every possible $x \in X$.
- We also have a prior distribution $\bel$ over the parameters.
- Given $x$, we calculate the posterior distribution
\begin{align}
\bel(\param | x)
& = \frac{P_\param(x) \bel(\param)}{\sum_{\param' \in \Params} P_{\param'}(x) \bel(\param')},
\tag{finite $\Params$}
\\
\bel(\param | x)
& = \frac{P_\param(x) \bel(\param)}{\int_{\Params} P_{\param'}(x) \bel(\param') d\param'},
\tag{continuous $\Params$}
\\
\bel(B | x)
& = \frac{\int_{B} P_{\param'}(x) d\bel(\param)}
{\int_{\Params}P_{\param'}(x) d\bel(\param)}
\tag{arbitrary $\Params$}
\end{align}
  
** Sufficient statistics
*** A statistic $f$
This is any function $f : X \to S$ where
- $X$ is the data space
- $S$ is an arbitrary space
*** Example statistics for $X = \Reals^*$ (the set of all real-valued sequences)
- The sample mean of a sequence $1/T \sum_{t=1}^T x_t$
- The total number of samples $T$
*** Sufficient statistic
$f$ is sufficient for a family $\{P_\param : \param \in \Params\}$ when
\[
f(x) = f(x') \Leftrightarrow P_\param(x) = P_\param(x') \forall \param \in \Params.
\]
** Conjugate priors

* Approximate Bayesian inference
** The Monte-Carlo Algorithm
** Gibbs Sampling and Markov Chain Monte-Carlo
