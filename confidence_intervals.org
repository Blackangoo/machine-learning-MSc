#+TITLE: Confidence Intervals
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \usepackage{tikz}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{amssymb}
#+LaTeX_HEADER: \usepackage{isomath}
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Var {\mathop{\mbox{\ensuremath{\mathbb{V}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Bias {\mathop{\mbox{\ensuremath{\mathbb{B}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \DeclareMathOperator*{\sgn}{sgn}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {B}
#+LaTeX_HEADER: \newcommand \param {\beta}
#+LaTeX_HEADER: \newcommand \vparam {\vectorsym{\beta}}
#+LaTeX_HEADER: \newcommand \mparam {\matrixsym{B}}
#+LaTeX_HEADER: \newcommand \bW {\matrixsym{W}}
#+LaTeX_HEADER: \newcommand \bw {\vectorsym{w}}
#+LaTeX_HEADER: \newcommand \wi {\vectorsym{w}_i}
#+LaTeX_HEADER: \newcommand \wij {w_{i,j}}
#+LaTeX_HEADER: \newcommand \bA {\matrixsym{A}}
#+LaTeX_HEADER: \newcommand \ai {\vectorsym{a}_i}
#+LaTeX_HEADER: \newcommand \aij {a_{i,j}}
#+LaTeX_HEADER: \newcommand \bx {\vectorsym{x}}
#+LaTeX_HEADER: \newcommand \by {\vectorsym{y}}
#+LaTeX_HEADER: \newcommand \bel {\beta}
#+LaTeX_HEADER: \newcommand \Ber {\textrm{Bernoulli}}
#+LaTeX_HEADER: \newcommand \Beta {\textrm{Beta}}
#+LaTeX_HEADER: \newcommand \Normal {\textrm{Normal}}
#+LaTeX_CLASS_OPTIONS: [smaller]
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3

* Hypothesis testing
** Which is the right model?

* Mean estimation
** Estimating a mean
*** The mean estimation
From data: $D =x_1, \ldots, x_T$, with $x_t \sim P$ and $\E_P(x_t) = \mu$, 
the empirical mean is

**** Empirical mean
\[
\hat{\mu}(D) = \frac{1}{T} \sum_{t=1}^T x_t.
\]
**** The error of the empirical mean
Since the data $D$ is random, what is the probability that our estimate is far away from $\mu$? Can we find constants $\epsilon, \delta > 0$ so that the following holds?
\[
\Pr[|\hat{\mu}(D) - \mu| > \epsilon] \leq \delta.
\]
This means that the probability that our error is large, is small.
**** Two methods:
- Distribution-specific confidence intervals
- Concentration inequalities

*** Distribution-specific intervals
**** Bernoulli 
If $x_t \sim \Ber{\mu}$, then the distribution of $\hat{\mu}$ is given by
the Binomial distribution! Hence, we can bound the probability
**** Normal  
If $x_t$ is normally-distributed with unknown mean, and variance 1, then the variance of $\hat{\mu}$ is $1/\sqrt{T}$, and its mean is $\hat{\mu}$. We can then use the standard normal tail bounds:
\[
\Pr(|\hat{\mu} - \mu| > \epsilon) \leq 2 e^{- \epsilon^2/2}
\]

*** Hoeffding's inequality



*** Chernoff bounds
