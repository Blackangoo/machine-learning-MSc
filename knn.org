#+TITLE: Machine Learning and Data Mining
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3


** Objective functions
*** Supervised learning objectives
- Data $(x_t, y_t)$, $x_t \in X$, $y_t \in Y$, $t \in [T]$.
- i.i.d assumption: $(x_t, y_t) \sim P$ for all $t$.
- Supervised decision rule $\pi(a_t | x_t)$
**** Classification
- Predict the labels correctly, i.e. $a_t = y_t$.
- Have an appropriate confidence level

**** Regression
- Predict the mean correctly
- Have an appropriate variance around the mean
*** Unsupervised learning objectives
- Reconstruct the data well
- Be able to generate data
*** Reinforcement learning objectives
- Maximise total reward

** $k$ Nearest Neighbours
*** The Nearest Neighbour algorithm
**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$
- $t^* = \argmin_t d(x_t, x)$
- Return $y^* = y_{t^*}$

**** Classification
     $y_t  \in [m] \equiv \{1, \ldots, m\}$
See example code

**** Regression
$y_t  \in \Reals^m$

*** The k-Nearest Neighbour algorithm

**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$, neighbours $k$
- Calculate $h_t = d(x_t, x)$ for all $t$.
- Get sorted indices $s = \texttt{argsort}(h)$ so that $d(x_{s_i}, x) \leq d(x_{s_{i+1}}, x)$ for all $i$.
- Return $\sum_{i=1}^k y_{s_i} / k$.

**** Classification
- It is not convenient to work with discrete labels
- We use a *one-hot encoding* vector representation $(0, \ldots, 0, 1, 0, \ldots, 0)$.
- $y_t \in \{0,1\}^m$ with $\|y_t\|_1 = 1$, so that the class of the $t$-th example is $j$ iff $y_{t,j} = 1$.

**** Regression
$y_t  \in \Reals^m$

*** Training and overfitting
**** Training data
- $D = ((x_t, y_t) : t = 1, \ldots, T)$.
- $x_t \in X$
- $y_t \in \Reals^m$.
**** Assumption: The data is generated i.i.d.
- $(x_t, y_t) \sim P$ for all $t$ (identical)
- $D \sim P^T$ (independent)
That is, if you know $P$, then knowing $(x_t, y_t)$ gives you no information about $(x_k, y_k)$.

**** The optimal decision rule for $P$
\[
\max_\pi U(\pi, P)
= 
\max_\pi \int_{X \times Y} dP(x, y) \sum_a \pi(a | x) U(a,y)
\]
**** The optimal decision rule for $D$
\[
\max_\pi U(\pi, D)
= 
\max_\pi \sum_{(x,y) \in D)} \sum_a \pi(a | x) U(a,y)
\]

*** Classification
**** The classifier as a decision rule
A decision rule $\pi(a | x)$ generates a *decision* $a \in [m]$. It is
the conditional probability of $a$ given $x$.

Even though normally conditional probabilities are defined as
$P(A | B) = P(A \cap B) / P(B)$, the probability of the decision $a$
is undefined without a given $x$. So it's better to 

**** The accuracy of a single decision
\[
U(a_t, y_t) = \ind{a_t = y_t}
 = \begin{cases}
1, & \textrm{if $a_t = y_t$}\\
0, & \textrm{otherwise}
\end{cases}
\]
\[
U(\pi, D) \defn \frac{1}{T} \sum_{t=1}^T \sum_{a=1}^m \pi(y_t | x_t)
\]


**** The accuracy on the training set
\[
U(\pi, D) \defn \frac{1}{T} \sum_{t=1}^T \sum_{a=1}^m \pi(y_t | x_t)
\]

**** The accuracy of a decision rule
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is the probability it predicts correctly
\[
U(\pi, P) \defn \int_X  dP(x) \sum_{y=1}^m P(y|x) \sum_{a=1}^m \pi(y | x)
\]


*** Regression



**** The regressor as a decision rule

A decision rule $\pi(a | x)$ generates a *decision* $a \in
\Reals^m$. It is the conditional density of $a$ given $x$.

**** The accuracy of a regressor
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is the probability it predicts correctly
\[
U(\pi, P) \defn - \int_X \sum_{y=1}^m dP(x, y) \sum_{a=1}^m \pi(a | x)
\]




