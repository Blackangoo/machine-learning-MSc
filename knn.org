#+TITLE: Nearest Neighbour Algorithms
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3

* Introduction
** The hidden secret of machine learning
*** The kNN algorithm idea
- Given labelled training examples..
- Assume an unknown example is similar to its neighbours
- Smoothness!

*** Performance of KNN on image classification
[[./fig/knn-image-performance.png]]


* The algorithm
  
** $k$ Nearest Neighbours
*** The Nearest Neighbour algorithm

**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$
- $t^* = \argmin_t d(x_t, x)$
- Return $y^* = y_{t^*}$

**** Classification
     $y_t  \in [m] \equiv \{1, \ldots, m\}$

**** Regression
$y_t  \in \Reals^m$

*** The k-Nearest Neighbour algorithm

**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$, neighbours $k$
- Calculate $h_t = d(x_t, x)$ for all $t$.
- Get sorted indices $s = \texttt{argsort}(h)$ so that $d(x_{s_i}, x) \leq d(x_{s_{i+1}}, x)$ for all $i$.
- Return $\sum_{i=1}^k y_{s_i} / k$.
  
**** Classification
- It is not convenient to work with discrete labels.
- We use a *one-hot encoding* vector representation $(0, \ldots, 0, 1, 0, \ldots, 0)$.
- $y_t \in \{0,1\}^m$ with $\|y_t\|_1 = 1$, so that the class of the $t$-th example is $j$ iff $y_{t,j} = 1$.

**** Regression
$y_t  \in \Reals^m$

* Extensions and parameters
** Neighbourhood calculation

** Distance function
*** Norms and semi-norms
**** A norm $d$
- Zero element $\|0\| = 0$.
- Homogeneity $\|cx\| = c \|x\|$ for any scalar $a$.
- Triangle inequality $\|x + y\| \leq \|x\| + \|y\|$.

**** $p$-norm
\[d(x,y) = \|x - y\|_p\]
with
\[
\|z\|_p = \left(\sum_i z_i^p\right)^p
\]
