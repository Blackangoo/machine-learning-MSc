#+TITLE: Machine Learning and Data Mining
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3

* The problems of Machine Learning (2 weeks)
#+TOC: headlines [currentsection]
** Models, hypotheses
*** Data collection
- Why do we need data?
- What data do we need?
- How much data do we want?
- How will we collect the data?
*** Models from data
**** Prediction
- Will it rain tomorrow?
- How much will bitcoin be worth next year?

**** Inference
- Does my poker opponent have two aces?
- What is the mass of the moon?
- What is the law of gravitation?

**** Decision Making
- Should I go hiking tomorrow?
- Should I buy some bitcoins?
- Should I fold, call, or raise in my poker game?

*** Learning from data
**** Unsupervised learning
- Given data $x_1, \ldots, x_T$.
- How is the data generated?

**** Supervised learning
- Given data $(x_1, y_1), \ldots, (x_T, y_T)$
- Learn about the relationship between $x_t$ and $y_t$

**** Reinforcement learning
- No data is given: the agent acts to obtain data.
- Learn to act in an *unknown* world through interaction and reward
  feedback.



* Learning as Optimisation (4 weeks)
#+TOC: headlines [currentsection]
** Objective functions
*** Supervised learning objectives
**** Classification
- Predict the labels correctly
- Have an appropriate confidence level
**** Regression
- Predict the mean correctly
- Have an appropriate variance around the mean
*** Unsupervised learning objectives
- Reconstruct the data well
- Be able to generate data
*** Reinforcement learning objectives
- Maximise total reward

** $k$ Nearest Neighbours
*** The Nearest Neighbour algorithm
**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$
- Find $t^* \in \argmin_{t} d(x_t, x)$:
  - $D = \infty$, $t^* = \emptyset$.
  - For $t \in 1, \ldots, T$:
    - If $d(x_t) < D$: $D = d(x_t), t^* = t$.
  - EndFor
- Return $y^* = y_{t^*}$

** Linear neural networks
*** Simple linear regression
**** Input and output
- Data pairs $(x_t, y_t)$, $t = 1, \ldots, T$.
- Input $x_t \in \Reals^n$
- Output $y_t \in \Reals$.

**** Parametrised function
- Parameters $\param \in \Reals^n$
- Function $f_\param : \Reals^n \to \Reals$, defined as
\[
f_\param(x_t) = \param^\top x_{t} = \sum_{i=1}^n \param_i x_{t,i}
\]

**** Optimisation goal: Miniminise mean-squared error.
\[
\min_\param \sum_t [y_t - f_\param(x_t)]^2
\]

** Multi-layer neural networks
* Learning as Probabilistic Inference (4 weeks)
** Probabilistic Models
#+TOC: headlines [currentsection]
* Reinforcement Learning (2 weeks)
#+TOC: headlines [currentsection]
* Mathematical background
#+TOC: headlines [currentsection]
** Probability background
***  Probability facts
**** Axioms of probability
- $P(\Omega) = 1$
- If $A \cap B = \emptyset$ then $P(A \cup B) = P(A) + P(B)$.
- $P(\emptyset) = 0$.
**** Marginalisation
If $A_1, \ldots, A_n$ are a partition of $\Omega$
\[
P(B) = \sum_{i = 1}^n P(B \cap A_i).
\]

*** Expectation
For any random variable $f: \Omega \to \Reals$, the expectation with respect to a probability measure $P$ is
\[
\E_P(f) = \sum_{\omega \in \Omega} f(\omega) P(\omega).
\]
*** Conditional probability
The conditional probability of an event $A$ given an event $B$ is defined as 
\[
P(A | B) = \frac{P(A \cap B)}{P(B)}
\]
*** Conditional expectation
The conditional expectation of a random variable $f: \Omega \to \Reals$, with respect to a probability measure $P$ conditioned on some event $B$ is simply
\[
\E_P(f | B) = \sum_{\omega \in \Omega} f(\omega) P(\omega | B).
\]

*** The theorem of Bayes
**** Bayes's theorem
    :PROPERTIES:
    :BEAMER_env: theorem
    :END:
\[
P(A | B) = \frac{P(B | A)}{P(B)} 
\]
#+BEAMER: \pause

**** The general case
If $A_1, \ldots, A_n$ are a partition of $\Omega$, meaning that they
are mutually exclusive events (i.e. $A_i \cap A_j = \emptyset$ for $i
\neq j$) such that one of them must be true (i.e. $\bigcup_{i=1}^n A_i =
\Omega$), then
\[
P(B) = \sum_{i=1}^n P(B | A_i) P(A_i)
\]
and 
\[
P(A_j | B) = \frac{P(B | A_j)}{\sum_{i=1}^n P(B | A_i) P(A_i)}
\]


** Calculus
*** Univariate caclulus
**** Derivative 
The derivative of a single-argument function is defined as:
\[
\frac{d}{dx} f(x) = \lim_{\epsilon \to 0} \frac{f(x + \epsilon) - f(x)}{\epsilon}.
\]
$f$ must be absolutely continuous at $x$ for the derivative to exist.

**** Riemann integral
If $\frac{d}{dx} F = f$ then its integral from $a$ to $b$ is:
\[
\int_a^b f(x) dx = F(b) - F(a),
\]

**** Fundamental theorem of calculus
\[
F(x) = \int_a^x f(x) dx \qquad \Rightarrow \qquad f(x) = \frac{d}{dx} F(x).
\]

*** Multivariate calculus

Consider a function $f: \Reals^n \to \Reals$. 
- Any $x \in \Reals^n$ is decomposed into $x = (x_1, \ldots, x_n)$, with each $x_i \in \Reals^n$.
- We write $f(x)$ instead of $f(x_1, \ldots, x_n)$.

**** Partial derivative
The partial derivative of $f$ with respect to its \(i\)-th argument is:
\[
\frac{\partial}{\partial x_i} f(x)
\]
is the derivative of the function $f_i$ where all terms other than $x_i$ are held constant.

**** Gradient
The gradient of $f$ with respect to all its arguments is the column vector of partial derivatives
\[
\nabla_x f(x) = 
\left(
\frac{\partial}{\partial x_1} f(x)
\cdots
\frac{\partial}{\partial x_i} f(x)
\cdots
\frac{\partial}{\partial x_n} f(x)
\right)^\top
\]
