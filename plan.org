#+TITLE: Machine Learning and Data Mining
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \usepackage{tikz}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{amssymb}
#+LaTeX_HEADER: \usepackage{isomath}
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \DeclareMathOperator*{\sgn}{sgn}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+LaTeX_HEADER: \newcommand \vparam {\vectorsym{\theta}}
#+LaTeX_HEADER: \newcommand \mparam {\matrixsym{\Theta}}
#+LaTeX_HEADER: \newcommand \bW {\matrixsym{W}}
#+LaTeX_HEADER: \newcommand \bw {\vectorsym{w}}
#+LaTeX_HEADER: \newcommand \wi {\vectorsym{w}_i}
#+LaTeX_HEADER: \newcommand \wij {w_{i,j}}
#+LaTeX_HEADER: \newcommand \bA {\matrixsym{A}}
#+LaTeX_HEADER: \newcommand \ai {\vectorsym{a}_i}
#+LaTeX_HEADER: \newcommand \aij {a_{i,j}}
#+LaTeX_HEADER: \newcommand \bx {\vectorsym{x}}
#+LaTeX_HEADER: \newcommand \bel {\beta}
#+LaTeX_HEADER: \newcommand \Ber {\textrm{Bernoulli}}
#+LaTeX_HEADER: \newcommand \Beta {\textrm{Beta}}
#+LaTeX_HEADER: \newcommand \Normal {\textrm{Normal}}


#+LaTeX_CLASS_OPTIONS: [smaller]
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3

This course gives an introduction to the algorithms and theory of
machine learning. Application is in the form of a course project.
During the course, you will be able to:

- Formulate machine learning problems in terms of opimisation or probabilistic inference.
- Understand the fundamental machine learning algorithms.
- Be able to implement some of the simplest algorithms.
- Apply off-the-shelf algorithms to problems.
- Develop custom models using algorithms from TensorFlow python library.

* Schedule

Here is a summary of the scheduled topics for this course, together
with the theory and practice focus, as well as which book chapters correspond to which lecture.

The course is split in two parts, the first focusing on
optimisation-based learning, and the second on probabilistic learning.

|------+-------+--------------------------------+------------------------+-----------------+------+---------|
| Week |  Date | Topic                          | Theory                 | Lab             | ISLP |    ESL2 |
|------+-------+--------------------------------+------------------------+-----------------+------+---------|
|    1 | 09.26 | Course Introduction            |                        | Pandas          |  1,2 | 2.1-2.2 |
|    2 | 10.03 | kNN                            | Generalisation         | pandas,sklearn  |    2 |     2.3 |
|    3 | 10.10 | Perceptron                     | Convergence            | sklearn         | 10.1 |     4.5 |
|    4 | 10.17 | Linear Regression              | SGD, Least-Squares     | sklearn,pyTorch |    3 |         |
|    5 | 10.24 | Multi-Layer Neural Network     | Backpropagation        | pyTorch         |   10 |         |
|    6 | 10.31 | Neural Network Lab             | Network Architectures  | pyTorch         |   10 |         |
|------+-------+--------------------------------+------------------------+-----------------+------+---------|
|    7 | 11.07 | Discriminative Models          | Logistic Regression    | pyTorch         |  4.3 |         |
|    8 | 11.14 | Generative Models              | Bayes Classifier       | Python          |  4.4 |         |
|    9 | 11.21 | Latent-Variable Models         | EM, GMM                | pyTorch         |      |     8.5 |
|   10 | 11.28 | Regularisation                 | Non-linear programming | pyTorch         |      |         |
|   11 | 12.05 | Bayesian Inference             | Conjugate priors       | pyTorch         |      |         |
|   12 | 12.12 | Approximate Bayesian Inference | Monte-Carlo Methods    | pyTorch         |      |         |
|------+-------+--------------------------------+------------------------+-----------------+------+---------|
|   13 | 12.19 | Project Presentations          |                        |                 |      |         |
|------+-------+--------------------------------+------------------------+-----------------+------+---------|

* Material
** Textbooks
*** Primary
- Introduction to Statistical Learning with Python
https://hastie.su.domains/ISLP/ISLP_website.pdf
- Elements of Statistical Learning
https://hastie.su.domains/Papers/ESLII.pdf
*** Secondary
- Probabilistic Machine Learning: An Introduction
https://probml.github.io/pml-book/book1.html
https://github.com/probml/pml-book/releases/latest/download/book1.pdf
- Probabilistic Machine Learning: Advanced Topics
https://probml.github.io/pml-book/book2.html
https://github.com/probml/pml2-book/releases/latest/download/book2.pdf

* The problems of Machine Learning (1 week)
#+TOC: headlines [currentsection,hideothersubsections]
** Introduction
*** Machine learning
**** Data Collection
- Downloading a clean dataset from a repository
- Performing a survey
- Scraping data from the web
- Deploying sensors, performing experiments, and obtaining measurements.
**** Modelling (what we focus on this course)
- Can be as simple as counting coin tosses.
- Can be as complex as a large language model with billions of parameters
- The model depends on the data and the problem
**** Decision Making
- Ultimately, we use models to make decisions.
- However, decisions are made every step of the way (how to collect data, which model to choose)
  
** Activities
*** Class data
**** Fill in your data (does not have to be true)

** Models, hypotheses
*** The main problems in machine learning and statistics
**** Prediction
- Will it rain tomorrow?
- How much will bitcoin be worth next year?

**** Inference
- Does my poker opponent have two aces?
- What is the mass of the moon?
- What is the law of gravitation?

**** Decision Making
- Should I go hiking tomorrow?
- Should I buy some bitcoins?
- Should I fold, call, or raise in my poker game?
- How can I get a spaceship to orbit the moon?

*** The need to learn from data
**** Problem definition
- What problem do we need to solve?
- How can we formalise it?
- What properties of the problem can we learn from data?

**** Data collection
- Why do we need data?
- What data do we need?
- How much data do we want?
- How will we collect the data?

**** Modelling and decision making
- How will we compute something useful?

*** Learning from data
**** Unsupervised learning
- Given data $x_1, \ldots, x_T$.
- Learn about the data-generating process.
  
**** Supervised learning
- Given data $(x_1, y_1), \ldots, (x_T, y_T)$
- Learn about the relationship between $x_t$ and $y_t$.
- Example: Classification, Regression
**** Online learning
- Sequence prediction: At each step $t$, predict $x_{t+1}$ from $x_1, \ldots, x_t$.
- Conditional prediction: At each step $t$, predict $y_{t+1}$ from $x_1, y_1 \ldots, x_t, y_t, \alert{x_{t+1}}$
**** Reinforcement learning
 Learn to act in an *unknown* world through interaction and rewards
** Examples
*** Unsupervised learning
**** Image compression
- Learn two mappings $c, d$
- $c(x)$ compresses an image $x$ to a small representation $z$.
- $d(z)$ decompresses to an approximate image $\hat{x}$.

*** Supervised learning
**** Image classification

*** Unsupervised learning
**** Density estimation
**** Compression
**** Generative modelling

** Pitfalls
*** Pitfalls
**** Reproducibility
- Modelling assumptions
- Distribution shift
- Interactions and feedback
**** Fairness
- Implicit biases in training data
- Fair decision rules and meritocracy
**** Privacy
- Accidental data disclosure
- Re-identification risk

* Learning as Optimisation (4 weeks)
  #+TOC: headlines [currentsection,hideothersubsections]]
** Objective functions
*** Supervised learning objectives
- Data $(x_t, y_t)$, $x_t \in X$, $y_t \in Y$, $t \in [T]$.
- i.i.d assumption: $(x_t, y_t) \sim P$ for all $t$.
- Supervised decision rule $\pi(a_t | x_t)$
**** Classification
- Predict the labels correctly, i.e. $a_t = y_t$.
- Have an appropriate confidence level

**** Regression
- Predict the mean correctly
- Have an appropriate variance around the mean
*** Unsupervised learning objectives
- Reconstruct the data well
- Model the data-generating distribution
- Be able to generate data
*** Reinforcement learning objectives
- Maximise total expected reward, either
- during learning, or
- after learning is finished.

** $k$ Nearest Neighbours
*** A simple classification problem
**** Income distribution data:
- $x \in \{\textrm{M},\textrm{F}\}$, gender.
- $y \in \Reals$, income.
**** Problem
- Can we model the income distribution?

*** The Nearest Neighbour algorithm
**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$
- $t^* = \argmin_t d(x_t, x)$
- Return $y^* = y_{t^*}$

**** Classification
     $y_t  \in [m] \equiv \{1, \ldots, m\}$
See example code

**** Regression
$y_t  \in \Reals^m$

*** The k-Nearest Neighbour algorithm
**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$, neighbours $k$
- Calculate $h_t = d(x_t, x)$ for all $t$.
- Get sorted indices $s = \texttt{argsort}(h)$ so that $d(x_{s_i}, x) \leq d(x_{s_{i+1}}, x)$ for all $i$.
- Return $\sum_{i=1}^k y_{s_i} / k$.

**** Classification
- It is not convenient to work with discrete labels
- We use a *one-hot encoding* vector representation $(0, \ldots, 0, 1, 0, \ldots, 0)$.
- $y_t \in \{0,1\}^m$ with $\|y_t\|_1 = 1$, so that the class of the $t$-th example is $j$ iff $y_{t,j} = 1$.

**** Regression
$y_t  \in \Reals^m$

Code: 
** Learning and generalisation
*** The Train/Test methodology
**** Training data $D = ((x_t, y_t) : t = 1, \ldots, T)$.
- $x_t \in X$
- $y_t \in \Reals^m$.
**** Assumption: The data is generated i.i.d.
- $(x_t, y_t) \sim P$ for all $t$ (identical)
- $D \sim P^T$ (independent)

**** The optimal decision rule for $P$
\[
\max_\pi U(\pi, P)
= 
\max_\pi \int_{X \times Y} dP(x, y) \sum_a \pi(a | x) U(a,y)
\]
**** The optimal decision rule for $D$
\[
\max_\pi U(\pi, D)
= 
\max_\pi \sum_{(x,y) \in D)} \sum_a \pi(a | x) U(a,y)
\]
*** Generalisation 

**** Error due to mismatched objectives
The $\pi^*$ maximising $U(\pi, P)$ is not the $\hat{\pi}$ maximising $U(\pi, D)$.

**** Lemma
If $|U(\pi, P) - U(\pi, D)| \leq \epsilon$ for all $\pi$ then
\[
U(\hat{\pi}, D) \geq U(\pi^*, P) - 2 \epsilon.
\]

**** Error due to restricted classes
- We may use a constrained $\hat{\Pi} \subset \Pi$. 
- Then $\max_{\hat{\pi} \in \hat{\Pi}} U(\pi, P) \leq \max_{\pi \in \Pi} U(\pi, P)$.

*** Classification
**** The classifier as a decision rule
A decision rule $\pi(a | x)$ generates a *decision* $a \in [m]$. It is
the conditional probability of $a$ given $x$.

Even though normally conditional probabilities are defined as
$P(A | B) = P(A \cap B) / P(B)$, the probability of the decision $a$
is undefined without a given $x$. So it's better to 

**** The accuracy of a single decision
\[
U(a_t, y_t) = \ind{a_t = y_t}
 = \begin{cases}
1, & \textrm{if $a_t = y_t$}\\
0, & \textrm{otherwise}
\end{cases}
\]
\[
U(\pi, D) \defn \frac{1}{T} \sum_{t=1}^T \sum_{a=1}^m \pi(y_t | x_t)
\]


**** The accuracy on the training set
\[
U(\pi, D) \defn \frac{1}{T} \sum_{t=1}^T \sum_{a=1}^m \pi(y_t | x_t)
\]

**** The expected accuracy of a decision rule
If $(x, y) \sim P$, the accuracy $U$ of a stochastic decision rule $\pi$
under the distribution $P$ is the probability it predicts correctly
\[
U(\pi, P) \defn \int_X  dP(x) \sum_{y=1}^m P(y|x) \pi(y | x)
\]

**** The log-accuracy
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is 
\[
U(\pi, P) \defn \int_X  dP(x) \sum_{y=1}^m P(y|x) \ln \pi(y | x)
\]

*** Regression

**** The regressor as a decision rule

A decision rule $\pi(a | x)$ generates a *decision* $a \in \Reals^m$.
It is the conditional density of $a$ given $x$.

**** Accuracy
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is:
\[
U(\pi, P) \defn \int_X \int_Y dP(x, y) \pi(y | x).
\]

**** Mean-Squared Error
If $(x, y) \sim P$, the mean-square error of a deterministic decision rule $\pi : X \to \Reals$
under the distribution $P(x,y) = P(x | y) P(y)$ is:
\[
\int_X \sum_{y=1}^m dP(x| y) P(y) \sum_{a=1}^m \pi(a | x)
\]

** Linear neural networks
*** The perceptron algorithm
**** Input
- Feature space $X \subset \Reals^n$.
- Label space $Y = \{-1, 1\}$.
- Data $(x_t, y_t)$, $t \in [T]$,  with $x_t \in X, y_t in Y$.
**** Algorithm
- $w_1 = w_0$.

- For $t = 1, \ldots, T$.
-- $a_t = \sgn(w_t^\top x_t)$.
-- If $a_t \neq y_t$
--- $w_{t+1} = w_t + y_t x_t$
-- Else
--- $w_{t+1} = $w_t$
- Return $w_{T+1}$
**** Theorem
 The number of mistakes made by the perceptron algorithm is bounded by
 $(r/\rho)^2$, where $\|x_t\|\leq r$, $\rho \leq y_t (v^\top x_t) /
 \|v\|$ for some *margin* $\rho$ and *hyperplane* $v$.
	 
*** Perceptron examples
**** Example 1: One-dimensional data
- Done on the board
- Shows how the algorithm works.
- Demonstrates the idea of a margin

**** Example 2: Two-dimensional data
- See [[file:src/NeuralNetworks/perceptron.py][in-class programming exercise]]

*** Python concepts
****  Numpy
- np.random.multivariate_normal(): generate samples from an n-D normal distribution
- np.random.choice(): generate samples from a discrete distribution
- np.zeros(): generate an array of zeros
- np.array(): create an array from a list
- np.block(): make an array from nested lists
- np.dot(): calculate the dot (aka inner) product
**** matplotlib.pyplot
- plt.plot(): Plot lines and points
- plt.axis(): manipulate axes
- plt.grid(): show a grid
- plt.show(): display the plot

*** Gradient methods example
**** Estimate the expected value
$x_t \sim P$ with $\E_P[x_t] = \mu$.
**** Objective
\[
\min_\param \E_P[(x_t - \param)^2].
\]
**** Derivative
Idea: at the minimum the derivative should be zero.
\[
d/d\param \E_P[(x_t - \param)^2]
= \E_P[d/d\param(x_t - \param)^2]
= \E_P[-(x_t - \param)]
= \E_P[x_t] - \param.
\]

Setting the derivative to 0, we have $\param = \E_P[x_t]$. This is a simple solution.
**** Real-world setting
- The objective function does not result in a simple solution
- The distribution $P$ is not known.
- We can sample $x \sim P$.

*** Stochastic gradient for mean estimation
\begin{align*}
 \frac{d}{d\param} \E_P [(x - \param)^2] 
&= \int_{-\infty}^\infty dP(x) \frac{d}{d\param} (x - \param)^2
\\
&=  \frac{d}{d\param} \int_{-\infty}^\infty dP(x) (x - \param)^2
\end{align*}

*** Simple linear regression
**** Input and output
- Data pairs $(x_t, y_t)$, $t = 1, \ldots, T$.
- Input $x_t \in \Reals^n$
- Output $y_t \in \Reals$.
**** Predicting the conditional mean $\E[y_t | x_t]$
- Parameters $\param \in \Reals^n$
- Function $f_\param : \Reals^n \to \Reals$, defined as
\[
f_\param(x_t) = \param^\top x_{t} = \sum_{i=1}^n \param_i x_{t,i}
\]

**** Optimisation goal: Miniminise mean-squared error.
\[
\min_\param \sum_{t=1}^T [y_t - \pi_\param(x_t)]^2
\]

How can we solve this problem?

*** Gradient descent algorithm
**** Minimising a function
\[
\min_\param f(\param) \geq f(\param') \forall \param',
\qquad \param^* = \argmin_\param f(\param) \Rightarrow f(\param^*) = \min_param f(\param)
\]
**** Gradient descent for minimisation
- Input $\param_0$
- For $n = 0, \ldots, N$:
- $\param_{n+1} = \param_n - \eta_n \nabla_\param f(\param_n)$
**** Step-size $\eta_n$
- $\eta_n$ fixed: for online learning
- $\eta_n = c/[c + n]$ for asymptotic convergence
- $\eta_n = \argmin_\eta f(\theta_n + \eta \nabla_\param)$: Line search.

*** Gradient desecnt for squared error
**** Cost function
\[
\ell(\param) =  \sum_{t=1}^T [y_t - \pi_\param(x_t)]^2
\]
**** Cost gradient
Using the chain rule of differentiation:
\begin{align*}
\nabla_\param \ell(\param)
&= \nabla \sum_{t=1}^T [y_t - \pi_\param(x_t)]^2
\\
&= \sum_{t=1}^T \nabla [y_t - \pi_\param(x_t)]^2
\\
&= \sum_{t=1}^T 2 [y_t - \pi_\param(x_t)] [- \nabla \pi_\param(x_t)]^2
\end{align*}
**** Parameter gradient
For a linear regressor:
\[
\frac{\partial}{\param_j} \pi_\param(x) = x_j.
\]

*** Analytical Least-Squares Solution

*** Stochastic gradient descent algorithm
**** Note
 :PROPERTIES:
 :BEAMER_ENV: note
 :END:
For the general case, we got to do this.

**** When $f$ is an expectation
\[
f(\param) = \int_X dP(x) g(x, \param).
\]
**** Replacing the expectation with a sample:
\begin{align*}
\nabla f(\param)
&= \int_X dP(x) \nabla g(x, \param)\\
&\approx \frac{1}{K} \sum_{k=1}^K \nabla g(x^{(k)}, \param), && x^{(k)} \sim P.
\end{align*}

** Multi-layer neural networks
*** Back-propagation
**** The chain rule
\[
f : X \to Z, \qquad g : Z \to Y,
\qquad \frac{dg}{dx} = \frac{dg}{df} \frac{df}{dx}
\]

**** Parametrised functions
\begin{align}
f: \mathcal{W} \times X \to Z, && g: \Omega \times Z \to Y, &&\pi = fg \tag{network mappings}
\\
\ell(D, \pi) = \sum_{(x,y) \in D} [y - \pi(x)]^2
\end{align}
**** Gradient descent with /back-propagation/
Apply the chain rule 
\[
\nabla_{w, \omega} \pi = \nabla_\omega
\]

*** Neural architectures

**** Layers
- Input to layer $x \in R^n$ 
- Output from layer $z \in R^m$.

**** Linear layer
Transform the output of previous layers or features into either:
- A higher-dimensional space.
- A lower-dimensional space.
- They have adaptive parameters.
- Parameters can be dependent on each other for invariance (cf. convolution)

**** Non-linear layers
- Simple transformations of previous output
- Examples: Sigmoid, Softmax

*** Liner layer
**** Definition
This is a linear combination of inputs $x \in \Reals^n$ and parameter matrix $\bW \in \Reals^{m \times n}$
where $\bW = \begin{bmatrix}
	\vectorsym{w}_1\\
        \vdots\\
	\wi\\
	\vdots\\
	\vectorsym{w}_m
\end{bmatrix}
=
\begin{bmatrix}
w_{1,1} & \cdots & w_{1,j} & \cdots & w_{1,m}\\
\vdots  & \ddots & \vdots  & \ddots & \cdots \\
w_{i,1} & \cdots & w_{i,j} & \cdots & w_{i,m}\\
\vdots  & \ddots & \ddots  & \ddots & \cdots \\ 	   
w_{n,1} & \cdots & w_{i,j} & \cdots & w_{n,m}
\end{bmatrix}$

\[
f(\bW, \bx) = \bW \bx 
\qquad
f_i(\bW, \bx)= \wi \cdot \bx =  \sum_{j=1}^n w_{i,j} x_i,
\]


**** Gradient 
Each partial derivative is simple:
\[
\frac{\partial}{\partial \wij} f_k(\bW, x) = x_i \ind{j = k}
\]

*** Sigmoid layer
**** Definition
This layer transforms each input non-linearly
\[
f_j(\bx) 1/[1 + \exp(-x_j)] =
\]
without looking at the other inputs.

**** Derivative
So let us ignore the other inputs for simplicity:
\[
\frac{d}{dx} f(x) = \exp(-x)/[1+\exp(-x)]^{2}
\]


**** Softmax 

* Learning as Probabilistic Inference (4 weeks)
** Probabilistic Models
*** Probabilistic modelling
**** The problem
- Model family $\{P_\param : \param \in \Param\}$
- Each model assigns a probability $P_\param(x)$ to the data $x$.
- How can we estimate $\param$ from $x$?
**** Maximum Likelihood (ML) Estimation
$\hat{\theta}(x) = \argmax_\theta P_\param(x)$.

**** Maximum A Posteriori (MAP) Estimation
Here we also need a prior distribution, but still estimate a single parameter:
- Prior $\bel(\param)$, a distribution on $\Param$.
- $\hat{\param}(x) = \argmax_\param P_\param(x) \bel(\param)$.
**** Bayesian Estimation
Here we estimate the complete distribution over parameters
- $\bel(\param | x) = P_\param(x) \bel(\param) / \sum_{\param'} P_{\param'}(x) \bel(\param')$ 

*** The Bernoulli distribution: Modelling a coin
**** Definition
If $x_t \sim \Ber(\param)$ then
$x_t = 1$ w.p. $\param$ and $x_t = 0$ w.p. $1 - \param$.
**** Likelihood function
 \(P(x_1, \ldots, x_T | \param) = \prod_{t=1}^T P(x_t | \param)\) = \prod_{t=1}^T \theta^{x_t} (1 - \theta)^{1 - x_t}
**** Maximum Likelihood Estimate
$\argmax_\param P(x | \param) = \argmax_\param \ln P(x | \param)$.
\begin{align*}
\frac{d}{d\param} \ln P(x | \param)
&=  \frac{d}{d\param} [\sum_t \ln P(x_t | \param)]
= \frac{d}{d\param} [\sum_t \ln \theta^{x_t} (1 - \theta)^{1 - x_t}]
\\
&=
\frac{d}{d\param}[ \ln (\theta) \sum_t x_t +  \ln (1 - \theta) \sum_t (1 - x_t)]
\\
&=
\frac{1}{\theta} \sum_t x_t  - \frac{1}{1 - \theta} \sum_t (1 - x_t)
\end{align*}
Setting the derivative to zero: \[\hat{\param}_T = \frac{1}{T} \sum_{t=1}^T x_t\]

*** Bayesian Estimate
**** The prior distribution $P(\param)$
$\param \sim \Beta(\alpha_1, \alpha_0)$
**** The likelihood function $P(x | \param)$
 \(P(x_1, \ldots, x_T | \param) = \prod_{t=1}^T P(x_t | \param)\)
**** The posterior distribution $P(\param | x)$
$\param \sim \Beta(\alpha_1 + \sum_{t=1}^T x_t, \alpha_0 + \sum_{t=1}^T x_t)$.

*** The Gaussian distribution: Modelling gambling gains
** Classification: Discriminative modelling
*** Discriminative modelling: general idea
- Data $(x,y)$
- Easier to model $P(y | x)$
- No need to model $P(x)$.
**** Examples
- Linear regression
- Logistic regression
- Multi-layer perceptron

*** Linear regression
**** Model
- $z = \param^\top x$
- $p_\param(y | x) = \frac{1}{\sqrt{2 \pi} \sigma} \exp(-\frac{1}{2 \sigma^2} |z - y|^2)$

*** Two-class classification: logistic regression
**** Model
- $z = \param^\top x$
- $P_\param(y = 1 | x) = \frac{1}{1 - e^z}$

** Classification: Generative modelling
   #+TOC: headlines [currentsection,hideothersubsections]
*** Generative modelling
**** general idea
- Data $(x,y)$.
- Need to model $P(y | x)$.
- Model the complet data distribution: $P(x | y)$, $P(x)$, $P(y)$.
- Calculate \(  P(y | x) = \frac{P(x | y) P(x)}{P(y)}. \)
**** Examples
- Naive Bayes classifier
- Gaussian Mixture Classifier
**** Modelling the data distribution
- Need to estimate the density $P(x | y)$ for each class $y$.

*** Classification: Naive Bayes Classifier
- Data $(x,y)$
- $x \in X$
- $y \in Y \subset \mathbb{N}$, $N_i$: amount of data from class $i$

  
**** Separately model each class
- Assume each class data comes from a different normal distribution
- $x | y = i \sim \Normal(\mu_i, \sigma_i I)$
- For each class, calculate
  - Empirical mean $\hat{\mu}_i = \sum_{t : y_t = i} x_t / N_i$
  - Empirical variance $\hat{\sigma}_i$.

**** Decision rule
Use Bayes's theorem:
\[
P(y | x) = P(x | y) P(y) / P(x),
\]
choosing the $y$ with largest posterior $P(y | x)$.
- $P(x | y = i) \propto \exp(- \|\hat{\mu}_i - x\|^2/\hat{\sigma}_i^2$
** Density estimation
*** General idea
**** Parametric models
- Fixed histograms
- Gaussian Mixtures
**** Non-parametric models
- Variable-bin histograms
- Infinite Gaussian Mixture Model
- Kernel methods

*** Histograms
**** Fixed histogram
- Hyper-Parameters: number of bins
- Parameters: Number of points in each bin.
**** Variable histogram
- Hyper-parameters: Rule for constructing bins
- Generally $\sqrt{n}$ points in each bin.

*** Gaussian Mixture Model
**** Hyperparameters:
- Number of Gaussian $k$.
**** Parameters:
- Multinomial distribution $\vparam$ over Gaussians
- For each Gaussian $i$, center $\mu_i$, covariance matrix $\Sigma_i$.
**** Model. For each point $x_t$:
- $c_t = i$ w.p. $\theta_i$
- $x_t | c_t = i \sim \Normal(\mu_i, \Sigma_i)$.
**** Algorithms:
- Expectation Maximisation
- Gradient Ascent
- Variational Bayesian Inference (with appropriate prior)

*** GMM with EM
**** Objective function: log-likelihood
\[
\ln P(x | \theta, \mu, \Sigma) = \ln \sum_i \theta_i P(x | \mu_i, \sigma_i)
\]

**** Expectation Step
**** Maximization Step


*** GMM Classifier :exercise:
**** Base class: sklearn GaussianMixtureModel
- /fit()/ only works for Density Estimaiton
- /predict()/ only predicts cluster labels
**** Problem
- Create a GMMClassifier class
- /fit()/ should take X, y, arguments
- /predict()/ should predict class labels
- Hint: Use /predict_proba()/ and multiple GMM models


* Sequence modelling (2 weeks)
** Sequence prediction
*** The problem of sequence prediction
- Data $x_1, x_2, x_3, \ldots$
- At time $t$, make a prediction $a_t$ for $x_t$.
*** Auto-regressive models
**** General idea
- Predict $x_{t}$ from the last $k$ inputs
\[
x_t \approx g(x_{t-k}, \ldots, x_{t-1})
\]
**** Optimisation view
We wish to minimise the difference between our predictions $a_t$ and the next symbol
\[
\sum_t (a_t - x_t)^2
\]
**** Probabilistic view
We wish to model
\[
P(x_t | x_{t-k}, \ldots, x_{t-1})
\]
*** Linear auto-regression
**** Simple time-series data
- Observations $x_t \in \Reals$
- Parameters $\vparam \in \Reals^k$
\[
\hat{x}_t = \sum_i \param_i x_{t-i}.
\]
**** Multi-dimensional time-series data
- Observations $x_t \in \Reals^n$
- Parameters $\mparam \in \Reals^{k \times n}$
\[
\hat{x}_t
= \sum_i \param^\top_i x_{t-i}.
= \sum_{i,j} \param_{i,j} x_{t-i}.
\]


*** Recursive models
**** General idea
- Maintain an /internal state/ $z_t$, which summarises what has been seen.
\[
z_t = f(z_{t-1}, x_{t-1}) \tag{change state}
\]
- Make predictions using the internal state
\[
\hat{x}_t = g(z_t) \tag{predict}
\]

**** Examples
- Hidden Markov models
- Recurrent Neural Networks

*** Hidden Markov Models: General setting
**** Variables
- State $z_t$
- Observations $x_t$
**** Parameters
- Transition $\theta$
- Observation $\psi$
**** Distributions
- Transition distribution $P_\theta(z_{t+1} | z_t)$
- Observation distribution $P_\psi(x_t | z_t)$.
*** HMMs: Discrete case
**** Variables
- State $z_t \in [n]$
- Observation $x_t \in [m]$
**** Transition distribution
Multinomial with 
\[
P_\theta(z_{t+1} = j | z_t = i) = \param_{i,j}
\]
**** Observation distribution
Multinomial with 
\[
P_\theta(x_t = j | z_t = i) = \psi_{i,j}
\]
*** HMMs: Continuous case
**** Variables
- State $z_t \in [n]$
- Observation $x_t \in \Reals^m$
**** Transition distribution
Multinomial with 
\[
P_\theta(z_{t+1} = j | z_t = i) = \param_{i,j}
\]
**** Observation distribution
Gaussian with 
\[
P_\theta(x_t = x | z_t = i) \propto \exp\left(-\|x - \psi_{i}\|\right)
\]
** Expectation Maximisation
*** Density Estimation with EM
*** HMM Estimation with EM

** Monte-Carlo Methods


* Reinforcement Learning (2 weeks)
#+TOC: headlines [currentsection,hideothersubsections]





