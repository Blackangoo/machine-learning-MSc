#+TITLE: Machine Learning and Data Mining
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3

* The problems of Machine Learning (1 week)
#+TOC: headlines [currentsection,hideothersubsections]
** Models, hypotheses
*** The main problems in machine learning and statistics
**** Prediction
- Will it rain tomorrow?
- How much will bitcoin be worth next year?

**** Inference
- Does my poker opponent have two aces?
- What is the mass of the moon?
- What is the law of gravitation?

**** Decision Making
- Should I go hiking tomorrow?
- Should I buy some bitcoins?
- Should I fold, call, or raise in my poker game?
- How can I get a spaceship to orbit the moon?

*** The need to learn from data
**** Problem definition
- What problem do we need to solve?
- How can we formalise it?
- What properties of the problem can we learn from data?

**** Data collection
- Why do we need data?
- What data do we need?
- How much data do we want?
- How will we collect the data?

**** Modelling and decision making
- How will we compute something useful?

*** Learning from data
**** Unsupervised learning
- Given data $x_1, \ldots, x_T$.
- Learn about the data-generating process.
  
**** Supervised learning
- Given data $(x_1, y_1), \ldots, (x_T, y_T)$
- Learn about the relationship between $x_t$ and $y_t$.

**** Reinforcement learning
- No data is given: the agent acts to obtain data.
- Learn to act in an *unknown* world through interaction and reward
  feedback.

*** Unsupervised learning
**** Density estimation
**** Clustering
**** Compression
*** Supervised learning
**** Classification
**** Regression
**** Sequence prediction
	 
* Learning as Optimisation (4 weeks)
#+TOC: headlines [currentsection,hideothersubsections]]
** Objective functions
*** Supervised learning objectives
- Data $(x_t, y_t)$, $x_t \in X$, $y_t \in Y$, $t \in [T]$.
- i.i.d assumption: $(x_t, y_t) \sim P$ for all $t$.
- Supervised decision rule $\pi(a_t | x_t)$
**** Classification
- Predict the labels correctly, i.e. $a_t = y_t$.
- Have an appropriate confidence level

**** Regression
- Predict the mean correctly
- Have an appropriate variance around the mean
*** Unsupervised learning objectives
- Reconstruct the data well
- Be able to generate data
*** Reinforcement learning objectives
- Maximise total reward

** $k$ Nearest Neighbours
*** The Nearest Neighbour algorithm
**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$
- $t^* = \argmin_t d(x_t, x)$
- Return $y^* = y_{t^*}$

**** Classification
     $y_t  \in [m] \equiv \{1, \ldots, m\}$
See example code

**** Regression
$y_t  \in \Reals^m$

*** The k-Nearest Neighbour algorithm

**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$, neighbours $k$
- Calculate $h_t = d(x_t, x)$ for all $t$.
- Get sorted indices $s = \texttt{argsort}(h)$ so that $d(x_{s_i}, x) \leq d(x_{s_{i+1}}, x)$ for all $i$.
- Return $\sum_{i=1}^k y_{s_i} / k$.

**** Classification
- It is not convenient to work with discrete labels
- We use a *one-hot encoding* vector representation $(0, \ldots, 0, 1, 0, \ldots, 0)$.
- $y_t \in \{0,1\}^m$ with $\|y_t\|_1 = 1$, so that the class of the $t$-th example is $j$ iff $y_{t,j} = 1$.

**** Regression
$y_t  \in \Reals^m$

*** Training and overfitting
**** Training data
- $D = ((x_t, y_t) : t = 1, \ldots, T)$.
- $x_t \in X$
- $y_t \in \Reals^m$.
**** Assumption: The data is generated i.i.d.
- $(x_t, y_t) \sim P$ for all $t$ (identical)
- $D \sim P^T$ (independent)

**** The optimal decision rule for $P$
\[
\max_\pi U(\pi, P)
= 
\max_\pi \int_{X \times Y} dP(x, y) \sum_a \pi(a | x) U(a,y)
\]
**** The optimal decision rule for $D$
\[
\max_\pi U(\pi, D)
= 
\max_\pi \sum_{(x,y) \in D)} \sum_a \pi(a | x) U(a,y)
\]
**** Mismatched objectives
The $\pi^*$ maximising $U(\pi, P)$ is not the $\hat{\pi}$ maximising $U(\pi, D)$.

**** Lemma
If $|U(\pi, P) - U(\pi, D)| \leq \epsilon$ for all $\pi$ then
\[
U(\hat{\pi}, D) \geq U(\pi^*, P) - 2 \epsilon.
\]

*** Classification
**** The classifier as a decision rule
A decision rule $\pi(a | x)$ generates a *decision* $a \in [m]$. It is
the conditional probability of $a$ given $x$.

Even though normally conditional probabilities are defined as
$P(A | B) = P(A \cap B) / P(B)$, the probability of the decision $a$
is undefined without a given $x$. So it's better to 

**** The accuracy of a single decision
\[
U(a_t, y_t) = \ind{a_t = y_t}
 = \begin{cases}
1, & \textrm{if $a_t = y_t$}\\
0, & \textrm{otherwise}
\end{cases}
\]
\[
U(\pi, D) \defn \frac{1}{T} \sum_{t=1}^T \sum_{a=1}^m \pi(y_t | x_t)
\]


**** The accuracy on the training set
\[
U(\pi, D) \defn \frac{1}{T} \sum_{t=1}^T \sum_{a=1}^m \pi(y_t | x_t)
\]

**** The expected accuracy of a decision rule
If $(x, y) \sim P$, the accuracy $U$ of a stochastic decision rule $\pi$
under the distribution $P$ is the probability it predicts correctly
\[
U(\pi, P) \defn \int_X  dP(x) \sum_{y=1}^m P(y|x) \pi(y | x)
\]

**** The log-accuracy
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is 
\[
U(\pi, P) \defn \int_X  dP(x) \sum_{y=1}^m P(y|x) \ln \pi(y | x)
\]


*** Regression

**** The regressor as a decision rule

A decision rule $\pi(a | x)$ generates a *decision* $a \in \Reals^m$.
It is the conditional density of $a$ given $x$.

**** Accuracy
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is:
\[
U(\pi, P) \defn \int_X \int_Y dP(x, y) \pi(y | x).
\]

**** Mean-Squared Error
If $(x, y) \sim P$, the mean-square error of a deterministic decision rule $\pi : X \to \Reals$
under the distribution $P$ is:
\[
\int_X \sum_{y=1}^m dP(x, y) \sum_{a=1}^m \pi(a | x)
\]

** Linear neural networks
*** The perceptron algorithm
**** Input
- Feature space $X \subset \Reals^n$.
- Label space $Y = \{-1, 1\}$.
- Data $(x_t, y_t)$, $t \in [T]$,  with $x_t \in X, y_t in Y$.
**** Algorithm
- $w_1 = w_0$.
- For $t = 1, \ldots, T$.
-- $a_t = \sgn(w_t^\top x_t)$.
-- If $a_t \neq y_t$
--- $w_{t+1} = w_t + y_t x_t$
-- Else
--- $w_{t+1} = $w_t$
- Return $w_{T+1}$
**** Theorem
	 The number of mistakes made by the perceptron algorithm is boudned by $(r/\rho)^2$, where $\|x_t\|\leq r$, $\rho \leq y_t (v^\top x_t) / \|v\|$ for some *margin* $\rho$ and *hyperplane* $v$.
	 
*** Gradient methods example
**** Estimate the expected value
$x_t \sim P$ with $\E_P[x_t] = \mu$.
**** Objective
\[
\min_\param \E_P[(x_t - \param)^2].
\]
**** Derivative
\[
d/d\param \E_P[(x_t - \param)^2]
= \E_P[d/d\param(x_t - \param)^2]
= \E_P[-(x_t - \param)]
= \E_P[x_t] - \param.
\]


*** Simple linear regression
**** Input and output
- Data pairs $(x_t, y_t)$, $t = 1, \ldots, T$.
- Input $x_t \in \Reals^n$
- Output $y_t \in \Reals$.

**** Predicting the mean
- Parameters $\param \in \Reals^n$
- Function $f_\param : \Reals^n \to \Reals$, defined as
\[
f_\param(x_t) = \param^\top x_{t} = \sum_{i=1}^n \param_i x_{t,i}
\]

**** Optimisation goal: Miniminise mean-squared error.
\[
\min_\param \sum_{t=1}^T [y_t - \pi_\param(x_t)]^2
\]
**** Gradient direction

*** Gradient descent algorithm
**** Minimising a function
\[
\min_\param \
\]
*** Stochastic gradient descent algorithm
** Multi-layer neural networks
*** Back-propagation
*** Neural architectures
* Learning as Probabilistic Inference (4 weeks)
** Probabilistic Models
** Discriminative modelling
*** Classification
**** Two-class classification: logistic regression

*** Regression
** Generative modelling
*** Classification
	Modelling two classes
*** Regression
#+TOC: headlines [currentsection,hideothersubsections]
* Sequence modelling (1 week)
** Auto-regressive models
** Recursive models

* Reinforcement Learning (2 weeks)
#+TOC: headlines [currentsection,hideothersubsections]





