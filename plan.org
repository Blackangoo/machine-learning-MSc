#+TITLE: Machine Learning and Data Mining
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \usepackage{tikz}
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \DeclareMathOperator*{\sgn}{sgn}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+LaTeX_CLASS_OPTIONS: [smaller]
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3

* Schedule

Here is a summary of the scheduled topics for this course, together
with the theory and practice focus.

|------+-------+--------------------------------+----------------------------------+--------------------|
| Week |  Date | Topic                          | Theory                           | Lab                |
|------+-------+--------------------------------+----------------------------------+--------------------|
|    1 | 09.19 | Course Introduction            |                                  | Pandas             |
|    2 | 09.26 | kNN                            | Generalisation                   | pandas,sklearn     |
|    3 | 10.03 | Perceptron                     | Convergence                      | sklearn            |
|    4 | 10.10 | Linear Regression              | SGD, Least-Squares               | sklearn,tensorflow |
|    5 | 10.17 | Multi-Layer Neural Network     | Backpropagation                  | tensorflow         |
|    6 | 10.24 | TensorFlow Lab                 | Network Architectures            | tensorflow         |
|    7 | 10.31 | Discriminative Models          | Logistic Regression              | TFProb             |
|    8 | 11.07 | Generative Models              | Bayes Classifier                 | Python             |
|    9 | 11.14 | Bayesian Networks              | Conditional Independence         | TFProb             |
|   10 | 11.21 | Regularisation                 | Non-linear programming           | tensorflow         |
|   11 | 11.28 | Bayesian Inference             | Conjugate priors                 | TFprob             |
|   12 | 12.05 | Approximate Bayesian Inference | Monte-Carlo Methods              | TFProb             |
|   13 | 12.12 | Bayesian Neural Networks       | Stochastic Variational Inference | TFProb             |
|   14 | 12.19 | Project Presentations          |                                  |                    |
|------+-------+--------------------------------+----------------------------------+--------------------|

* The problems of Machine Learning (1 week)
#+TOC: headlines [currentsection,hideothersubsections]
** Activities
*** Class data
**** Fill in your data (does not have to be true)

** Models, hypotheses
*** The main problems in machine learning and statistics
**** Prediction
- Will it rain tomorrow?
- How much will bitcoin be worth next year?

**** Inference
- Does my poker opponent have two aces?
- What is the mass of the moon?
- What is the law of gravitation?

**** Decision Making
- Should I go hiking tomorrow?
- Should I buy some bitcoins?
- Should I fold, call, or raise in my poker game?
- How can I get a spaceship to orbit the moon?

*** The need to learn from data
**** Problem definition
- What problem do we need to solve?
- How can we formalise it?
- What properties of the problem can we learn from data?

**** Data collection
- Why do we need data?
- What data do we need?
- How much data do we want?
- How will we collect the data?

**** Modelling and decision making
- How will we compute something useful?

*** Learning from data
**** Unsupervised learning
- Given data $x_1, \ldots, x_T$.
- Learn about the data-generating process.
  
**** Supervised learning
- Given data $(x_1, y_1), \ldots, (x_T, y_T)$
- Learn about the relationship between $x_t$ and $y_t$.
- Example: Classification, Regression
**** Online learning
- Sequence prediction: At each step $t$, predict $x_{t+1}$ from $x_1, \ldots, x_t$.
- Conditional prediction: At each step $t$, predict $y_{t+1}$ from $x_1, y_1 \ldots, x_t, y_t, \alert{x_{t+1}}$
**** Reinforcement learning
 Learn to act in an *unknown* world through interaction and rewards
** Examples
*** Unsupervised learning
**** Image compression
- Learn two mappings $c, d$
- $c(x)$ compresses an image $x$ to a small representation $z$.
- $d(z)$ decompresses to an approximate image $\hat{x}$.

*** Supervised learning
**** Image classification

*** Unsupervised learning
**** Density estimation
**** Compression
**** Generative modelling

** Pitfalls
*** Pitfalls
**** Reproducibility
- Modelling assumptions
- Distribution shift
- Interactions and feedback
**** Fairness
- Implicit biases in training data
- Fair decision rules and meritocracy
**** Privacy
- Accidental data disclosure
- Re-identification risk


* Learning as Optimisation (4 weeks)
  #+TOC: headlines [currentsection,hideothersubsections]]
** Objective functions
*** Supervised learning objectives
- Data $(x_t, y_t)$, $x_t \in X$, $y_t \in Y$, $t \in [T]$.
- i.i.d assumption: $(x_t, y_t) \sim P$ for all $t$.
- Supervised decision rule $\pi(a_t | x_t)$
**** Classification
- Predict the labels correctly, i.e. $a_t = y_t$.
- Have an appropriate confidence level

**** Regression
- Predict the mean correctly
- Have an appropriate variance around the mean
*** Unsupervised learning objectives
- Reconstruct the data well
- Model the data-generating distribution
- Be able to generate data
*** Reinforcement learning objectives
- Maximise total expected reward, either
- during learning, or
- after learning is finished.

** $k$ Nearest Neighbours
*** A simple classification problem
**** Income distribution data:
- $x \in \{\textrm{M},\textrm{F}\}$, gender.
- $y \in \Reals$, income.
**** Problem
- Can we model the income distribution?

*** The Nearest Neighbour algorithm
**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$
- $t^* = \argmin_t d(x_t, x)$
- Return $y^* = y_{t^*}$

**** Classification
     $y_t  \in [m] \equiv \{1, \ldots, m\}$
See example code

**** Regression
$y_t  \in \Reals^m$

*** The k-Nearest Neighbour algorithm
**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$, neighbours $k$
- Calculate $h_t = d(x_t, x)$ for all $t$.
- Get sorted indices $s = \texttt{argsort}(h)$ so that $d(x_{s_i}, x) \leq d(x_{s_{i+1}}, x)$ for all $i$.
- Return $\sum_{i=1}^k y_{s_i} / k$.

**** Classification
- It is not convenient to work with discrete labels
- We use a *one-hot encoding* vector representation $(0, \ldots, 0, 1, 0, \ldots, 0)$.
- $y_t \in \{0,1\}^m$ with $\|y_t\|_1 = 1$, so that the class of the $t$-th example is $j$ iff $y_{t,j} = 1$.

**** Regression
$y_t  \in \Reals^m$

** Learning and generalisation
*** The Train/Test methodology
**** Training data $D = ((x_t, y_t) : t = 1, \ldots, T)$.
- $x_t \in X$
- $y_t \in \Reals^m$.
**** Assumption: The data is generated i.i.d.
- $(x_t, y_t) \sim P$ for all $t$ (identical)
- $D \sim P^T$ (independent)

**** The optimal decision rule for $P$
\[
\max_\pi U(\pi, P)
= 
\max_\pi \int_{X \times Y} dP(x, y) \sum_a \pi(a | x) U(a,y)
\]
**** The optimal decision rule for $D$
\[
\max_\pi U(\pi, D)
= 
\max_\pi \sum_{(x,y) \in D)} \sum_a \pi(a | x) U(a,y)
\]
*** Generalisation error as mismatched objectives
The $\pi^*$ maximising $U(\pi, P)$ is not the $\hat{\pi}$ maximising $U(\pi, D)$.

**** Illustration
#+HEADER: :file circle.pdf :imagemagick yes
#+HEADER: :results output silent :headers '("\\usepackage{tikz}")
#+HEADER: :fit yes :imoutoptions -geometry 400 :iminoptions -density 600
#+BEGIN_SRC latex
  \begin{tikzpicture}
	\draw[->] (-3, 0) -- (4.2, 0) node[right] {$x$};
	\draw[->] (0, -3) -- (0, 4.2) node[above] {$y$};
	\draw[scale=0.5, domain=-3:3, smooth, variable=\x, blue] plot ({\x}, {\x*\x});
	\draw[scale=0.5, domain=-3:3, smooth, variable=\y, red]  plot ({\y*\y}, {\y});
  \end{tikzpicture}
#+END_SRC
[[./circle.pdf][Circle]]


**** Lemma
If $|U(\pi, P) - U(\pi, D)| \leq \epsilon$ for all $\pi$ then
\[
U(\hat{\pi}, D) \geq U(\pi^*, P) - 2 \epsilon.
\]

*** Classification
**** The classifier as a decision rule
A decision rule $\pi(a | x)$ generates a *decision* $a \in [m]$. It is
the conditional probability of $a$ given $x$.

Even though normally conditional probabilities are defined as
$P(A | B) = P(A \cap B) / P(B)$, the probability of the decision $a$
is undefined without a given $x$. So it's better to 

**** The accuracy of a single decision
\[
U(a_t, y_t) = \ind{a_t = y_t}
 = \begin{cases}
1, & \textrm{if $a_t = y_t$}\\
0, & \textrm{otherwise}
\end{cases}
\]
\[
U(\pi, D) \defn \frac{1}{T} \sum_{t=1}^T \sum_{a=1}^m \pi(y_t | x_t)
\]


**** The accuracy on the training set
\[
U(\pi, D) \defn \frac{1}{T} \sum_{t=1}^T \sum_{a=1}^m \pi(y_t | x_t)
\]

**** The expected accuracy of a decision rule
If $(x, y) \sim P$, the accuracy $U$ of a stochastic decision rule $\pi$
under the distribution $P$ is the probability it predicts correctly
\[
U(\pi, P) \defn \int_X  dP(x) \sum_{y=1}^m P(y|x) \pi(y | x)
\]

**** The log-accuracy
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is 
\[
U(\pi, P) \defn \int_X  dP(x) \sum_{y=1}^m P(y|x) \ln \pi(y | x)
\]

*** Regression

**** The regressor as a decision rule

A decision rule $\pi(a | x)$ generates a *decision* $a \in \Reals^m$.
It is the conditional density of $a$ given $x$.

**** Accuracy
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is:
\[
U(\pi, P) \defn \int_X \int_Y dP(x, y) \pi(y | x).
\]

**** Mean-Squared Error
If $(x, y) \sim P$, the mean-square error of a deterministic decision rule $\pi : X \to \Reals$
under the distribution $P(x,y) = P(x | y) P(y)$ is:
\[
\int_X \sum_{y=1}^m dP(x| y) P(y) \sum_{a=1}^m \pi(a | x)
\]

** Linear neural networks
*** The perceptron algorithm
**** Input
- Feature space $X \subset \Reals^n$.
- Label space $Y = \{-1, 1\}$.
- Data $(x_t, y_t)$, $t \in [T]$,  with $x_t \in X, y_t in Y$.
**** Algorithm
- $w_1 = w_0$.
- For $t = 1, \ldots, T$.
-- $a_t = \sgn(w_t^\top x_t)$.
-- If $a_t \neq y_t$
--- $w_{t+1} = w_t + y_t x_t$
-- Else
--- $w_{t+1} = $w_t$
- Return $w_{T+1}$
**** Theorem
 The number of mistakes made by the perceptron algorithm is boudned by
 $(r/\rho)^2$, where $\|x_t\|\leq r$, $\rho \leq y_t (v^\top x_t) /
 \|v\|$ for some *margin* $\rho$ and *hyperplane* $v$.
	 
*** Gradient methods example
**** Estimate the expected value
$x_t \sim P$ with $\E_P[x_t] = \mu$.
**** Objective
\[
\min_\param \E_P[(x_t - \param)^2].
\]
**** Derivative
Idea: at the minimum the derivative should be zero.
\[
d/d\param \E_P[(x_t - \param)^2]
= \E_P[d/d\param(x_t - \param)^2]
= \E_P[-(x_t - \param)]
= \E_P[x_t] - \param.
\]

Setting the derivative to 0, we have $\param = \E_P[x_t]$. This is a simple solution.
**** Real-world setting
- The objective function does not result in a simple solution
- The distribution $P$ is not known.
- We can sample $x \sim P$.

*** Stochastic gradient for mean estimation
\begin{align*}
 \frac{d}{d\param} \E_P [(x - \param)^2] 
&= \int_{-\infty}^\infty dP(x) \frac{d}{d\param} (x - \param)^2
\\
&=  \frac{d}{d\param} \int_{-\infty}^\infty dP(x) (x - \param)^2
\end{align*}

*** Simple linear regression
**** Input and output
- Data pairs $(x_t, y_t)$, $t = 1, \ldots, T$.
- Input $x_t \in \Reals^n$
- Output $y_t \in \Reals$.
**** Predicting the conditional mean $\E[y_t | x_t]$
- Parameters $\param \in \Reals^n$
- Function $f_\param : \Reals^n \to \Reals$, defined as
\[
f_\param(x_t) = \param^\top x_{t} = \sum_{i=1}^n \param_i x_{t,i}
\]

**** Optimisation goal: Miniminise mean-squared error.
\[
\min_\param \sum_{t=1}^T [y_t - \pi_\param(x_t)]^2
\]

How can we solve this problem?

*** Gradient descent algorithm
**** Minimising a function
\[
\min_\param f(\param) \geq f(\param') \forall \param',
\qquad \param^* = \argmin_\param f(\param) \Rightarrow f(\param^*) = \min_param f(\param)
\]
**** Gradient descent for minimisation
- Input $\param_0$
- For $n = 0, \ldots, N$:
- $\param_{n+1} = \param_n - \eta_n \nabla_\param f(\param_n)$
**** Step-size $\eta_n$
- $\eta_n$ fixed: for online learning
- $\eta_n = c/[c + n]$ for asymptotic convergence
- $\eta_n = \argmin_\eta f(\theta_n + \eta \nabla_\param)$: Line search.

*** Gradient descnt for squared error
**** Cost function
\[
\ell(\param) =  \sum_{t=1}^T [y_t - \pi_\param(x_t)]^2
\]
**** Cost gradient
Using the chain rule of differentiation:
\begin{align*}
\nabla_\param \ell(\param)
&= \nabla \sum_{t=1}^T [y_t - \pi_\param(x_t)]^2
\\
&= \sum_{t=1}^T \nabla [y_t - \pi_\param(x_t)]^2
\\
&= \sum_{t=1}^T 2 [y_t - \pi_\param(x_t)] [- \nabla \pi_\param(x_t)]^2
\end{align*}
**** Parameter gradient
For a linear regressor:
\[
\frac{\partial}{\param_j} \pi_\param(x) = x_j.
\]

*** Stochastic gradient descent algorithm
**** Note
 :PROPERTIES:
 :BEAMER_ENV: note
 :END:
For the general case, we got to do this.

**** When $f$ is an expectation
\[
f(\param) = \int_X dP(x) g(x, \param).
\]
**** Replacing the expectation with a sample:
\begin{align*}
\nabla f(\param)
&= \int_X dP(x) \nabla g(x, \param)\\
&\approx \frac{1}{K} \sum_{k=1}^K \nabla g(x^{(k)}, \param), && x^{(k)} \sim P.
\end{align*}

** Multi-layer neural networks
*** Back-propagation
**** The chain rule
\[
f : X \to Z, \qquad g : Z \to Y,
\qquad \frac{dg}{dx} = \frac{dg}{df} \frac{df}{dx}
\]

**** Parametrised functions
\begin{align}
f: \Theta \times X \to Z, && g: \Omega \times Z \to Y, &&\pi = fg \tag{network mappings}
\\
\ell(D, \pi) = \sum_{(x,y) \in D} [y - \pi(x)]^2
\end{align}
**** Gradient descent with /back-propagation/
Apply the chain rule 
\[
\nabla_{\theta, \omega} \pi = \nabla_\omega
\]

*** Neural architectures
* Learning as Probabilistic Inference (4 weeks)
** Probabilistic Models
** Discriminative modelling
*** Classification
**** Two-class classification: logistic regression

*** Regression
** Generative modelling
*** Classification
	Modelling two classes
*** Regression
#+TOC: headlines [currentsection,hideothersubsections]
* Sequence modelling (1 week)
** Auto-regressive models
** Recursive models

* Reinforcement Learning (2 weeks)
#+TOC: headlines [currentsection,hideothersubsections]





