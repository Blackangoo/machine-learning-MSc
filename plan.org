#+TITLE: Machine Learning and Data Mining
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3

* The problems of Machine Learning (1 weeks)
#+TOC: headlines [currentsection,hideothersubsections]
** Models, hypotheses
*** Data collection
- Why do we need data?
- What data do we need?
- How much data do we want?
- How will we collect the data?
*** Models from data
**** Prediction
- Will it rain tomorrow?
- How much will bitcoin be worth next year?

**** Inference
- Does my poker opponent have two aces?
- What is the mass of the moon?
- What is the law of gravitation?

**** Decision Making
- Should I go hiking tomorrow?
- Should I buy some bitcoins?
- Should I fold, call, or raise in my poker game?

*** Learning from data
**** Unsupervised learning
- Given data $x_1, \ldots, x_T$.
- How is the data generated?

**** Supervised learning
- Given data $(x_1, y_1), \ldots, (x_T, y_T)$
- Learn about the relationship between $x_t$ and $y_t$

**** Reinforcement learning
- No data is given: the agent acts to obtain data.
- Learn to act in an *unknown* world through interaction and reward
  feedback.



* Learning as Optimisation (4 weeks)
#+TOC: headlines [currentsection,hideothersubsections]]
** Objective functions
*** Supervised learning objectives
**** Classification
- Predict the labels correctly
- Have an appropriate confidence level
**** Regression
- Predict the mean correctly
- Have an appropriate variance around the mean
*** Unsupervised learning objectives
- Reconstruct the data well
- Be able to generate data
*** Reinforcement learning objectives
- Maximise total reward


** $k$ Nearest Neighbours
*** The Nearest Neighbour algorithm
**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$
- $t^* = \argmin_t d(x_t, x)$
- Return $y^* = y_{t^*}$

**** Classification
     $y_t  \in [m] \equiv \{1, \ldots, m\}$
See example code

**** Regression
$y_t  \in \Reals^m$

*** The k-Nearest Neighbour algorithm

**** Pseudocode
- Input: Data $(x_t, y_t)_{t=1}^T$, test point $x$, distance $d$, neighbours $k$
- Calculate $h_t = d(x_t, x)$ for all $t$.
- Get sorted indices $s = \texttt{argsort}(h)$ so that $d(x_{s_i}, x) \leq d(x_{s_{i+1}}, x)$ for all $i$.
- Return $\sum_{i=1}^k y_{s_i} / k$.

**** Classification
- It is not convenient to work with discrete labels
- We use a *one-hot encoding* vector representation $(0, \ldots, 0, 1, 0, \ldots, 0)$.
- $y_t \in \{0,1\}^m$ with $\|y_t\|_1 = 1$, so that the class of the $t$-th example is $j$ iff $y_{t,j} = 1$.

**** Regression
$y_t  \in \Reals^m$

*** Training and overfitting
**** Training data
- $D = ((x_t, y_t) : t = 1, \ldots, T)$.
- $x_t \in X$
- $y_t \in \Reals^m$.
**** The optimal decision rule for $P$
\[
\max_\pi U(\pi, P)
= 
\max_\pi \int_{X \times Y} dP(x, y) \sum_a \pi(a | x) U(a,y)
\]
**** The optimal decision rule for $D$
\[
\max_\pi U(\pi, D)
= 
\max_\pi \sum_{(x,y) \in D)} \sum_a \pi(a | x) U(a,y)
\]




*** Classification
**** The classifier as a decision rule
A decision rule $\pi(a | x)$ generates a *decision* $a \in [m]$. It is the conditional probability of $a$ given $x$.

**** The accuracy of a decision rule
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is the probability it predicts correctly
\[
U(\pi, P) \defn \int_X \sum_{y=1}^m dP(x, y) \sum_{a=1}^m \pi(y | x)
\]


**** The accuracy on the training set
\[
U(\pi, D) \defn \frac{1}{T} \sum_{t=1}^T \sum_{a=1}^m \pi(y_t | x_t)
\]


*** Regression



**** The regressor as a decision rule
A decision rule $\pi(a | x)$ generates a *decision* $a \in \Reals^m$. It is the conditional density of $a$ given $x$.

**** The accuracy of a regressor
If $(x, y) \sim P$, the accuracy $U$ of a decision rule $\pi$
under the distribution $P$ is the probability it predicts correctly
\[
U(\pi, P) \defn - \int_X \sum_{y=1}^m dP(x, y) \sum_{a=1}^m \pi(a | x)
\]





** Linear neural networks
*** Simple linear regression
**** Input and output
- Data pairs $(x_t, y_t)$, $t = 1, \ldots, T$.
- Input $x_t \in \Reals^n$
- Output $y_t \in \Reals$.

**** Parametrised function
- Parameters $\param \in \Reals^n$
- Function $f_\param : \Reals^n \to \Reals$, defined as
\[
f_\param(x_t) = \param^\top x_{t} = \sum_{i=1}^n \param_i x_{t,i}
\]

**** Optimisation goal: Miniminise mean-squared error.
\[
\min_\param \sum_t [y_t - f_\param(x_t)]^2
\]

** Multi-layer neural networks
* Learning as Probabilistic Inference (4 weeks)
** Probabilistic Models
#+TOC: headlines [currentsection,hideothersubsections]
* Reinforcement Learning (2 weeks)
#+TOC: headlines [currentsection,hideothersubsections]

